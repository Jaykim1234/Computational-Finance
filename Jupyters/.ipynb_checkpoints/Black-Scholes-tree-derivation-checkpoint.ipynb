{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivation of the Black-Scholes formula from the binomial tree\n",
    "* This notebook is an extension of the week 5 slides for Computational Finance. It includes additional steps of the derivation of the Black-Scholes formula from the binomial tree for a European call option.\n",
    "\n",
    "* The derivation is divided in two parts:\n",
    "    1. We start with deriving the closed form expression for European call options based on a given tree.\n",
    "    * Next, we let $N \\rightarrow \\infty$ to derive the Black-Scholes formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Closed Form for European Options\n",
    "\n",
    "* The price of a European option\n",
    "<br>\n",
    "$$\n",
    "C_0=e^{-rT}\\mathbb{E}^\\mathbb{Q}\\left[\\max(S_T-K,0)\\right]\n",
    "$$\n",
    "<br>\n",
    "depends only on $S_T$, so there is no need to use a tree explicitly to evaluate it.\n",
    "<br><br>\n",
    "* Let $k$ denote the number of up moves of the stock , so that $N-k$ is the number of down moves. Then\n",
    "<br><br>\n",
    "$$\n",
    "S_T=S_0u^kd^{N-k}= u^k u^{-(N-k)}=S_0u^{2k-N},\n",
    "$$\n",
    "<br>\n",
    "where we use that $u = 1/d = d^{-1}$.\n",
    "* Under $\\mathbb{Q}$, $k\\sim\\mathrm{Bin}(N,p)$, with pmf $f(k;N,p)={N\\choose k} p^k (1-p)^{N-k}$. Thus\n",
    "$$\n",
    "C_0=e^{-rT}\\sum_{k=0}^N f(k;N,p) \\max(S_0u^kd^{N-k}-K,0).\n",
    "$$\n",
    "* Note that this is an extension of the one period case: if $N=1$, then $f(0;1,p) = (1-p)$ and $f(1;1,p)=p$ and we get the risk-neutral pricng formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* For the cases that $S_T > K$, the maximum in the sum is zero and adds nothing to the value of the option. Therefore, we only have to consider the non-zero pay-offs, i.e. when $S_T > K$. Since the finaly payoff only increases in $k$, we need to find the values of $k$ for which this holds to truncate the sum.\n",
    "*  Let $a$ denote the minimum number of up moves so that $S_T>K$, i.e., it should hold that \n",
    "<br>\n",
    "\\begin{align*}\n",
    "S_T =  S_0 u^{2k-N} &> K \\\\\n",
    "u^{2k-N} &> K/S_0,\n",
    "\\end{align*}\n",
    "taking logs on both sides gives\n",
    "\\begin{align*}\n",
    "(2k-N)\\log(u) &> \\log(K/S_0) \\\\\n",
    "2k-N &> \\log(K/S_0) / \\log(u) \\\\\n",
    "k &> N/2+\\log(K/S_0)/(2\\log u).\n",
    "\\end{align*}\n",
    "<br>\n",
    "This implies that $S_T > K$ if $k$ is any of the integers greater than $N/2+\\log(K/S_0)/(2\\log u)$.\n",
    "Note that Hull (2012) uses $\\log(K/S_0) = -\\log(S_0/K)$.\n",
    "\n",
    "* Let $a$ denote the minimum number of up moves so that $S_T>K$, i.e., it should hold that $a$ is the smallest integer greater than $N/2+\\log(K/S_0)/(2\\log u)$. Then\n",
    "<br><br>\n",
    "$$\n",
    "C_0=e^{-rT}\\sum_{k=a}^N f(k;N,p) \\left[S_0u^kd^{N-k}-K\\right].\n",
    "$$\n",
    "<br>\n",
    "* We can divide this into the sum of two terms: \n",
    "$$\n",
    "C_0=e^{-rT}\\sum_{k=a}^N f(k;N,p) S_0u^kd^{N-k} - e^{-rT}\\sum_{k=a}^N f(k;N,p) K.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The *second term* is \n",
    "\\begin{align*}\n",
    "\\left[\\sum_{k=a}^N f(k;N,p)\\right] e^{-rT} K &= \\left[ \\sum_{k=a}^N f(k;N,p)\\right] e^{-rT} K\\\\\n",
    "&=[1-F(a-1;N,p)]e^{-rT}K \\\\\n",
    "&=\\bar F(a-1;N,p)e^{-rT}K,\n",
    "\\end{align*}\n",
    "<br>\n",
    "where $F$ is the binomial cdf and $\\bar F$ is the survivor function.\n",
    "* To derive the above expression, we use (i) that the binomial cdf is (by definition) $F(x;N,p) = \\sum_{k=1}^x f(k;N,p)$, (ii) that $F(x;N,p) = 1$ because the probabilities should sum to one, and (iii) that the survivor function is $\\bar{F}(k;N,p) = 1-F(k;N,p)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let $p_\\ast= \\frac{p u}{pu + (1-p) d} = e^{-r\\delta t} p u $, where we use that $pu + (1-p) d = \\mathbb{E}^\\mathbb{Q}\\left[R_i\\right] = e^{r \\delta t}$. Note that $1-p_\\ast = 1 - \\frac{p u}{pu + (1-p) d} = \\frac{(1-p) d}{pu + (1-p) d} = e^{-r\\delta t} (1-p) d  $.\n",
    "\n",
    "* The *first term* of the sum is\n",
    "<br>\n",
    "\\begin{align*}\n",
    "e^{-rT}S_0\\sum_{k=a}^N  {N\\choose k} p^k (1-p)^{N-k} u^kd^{N-k} &= S_0\\sum_{k=a}^N  {N\\choose k} [e^{-r\\delta t} p u]^k [e^{-r \\delta t}(1-p) d]^{N-k} \\\\\n",
    "&= S_0\\sum_{k=a}^N  {N\\choose k} p_\\ast^k (1-p_\\ast)^{N-k},\n",
    "\\end{align*}\n",
    "where we use that $e^{r T} = e^{r\\delta t N} = e^{r\\delta tk} e^{r\\delta t(N-k)}$.\n",
    "* Then, in the same as how we got the expression for the second term, we have that the first term can be written as\n",
    "$$\n",
    "S_0\\sum_{k=a}^N  {N\\choose k} p_\\ast^k (1-p_\\ast)^{N-k} = S_0\\bar F(a-1;N,p_\\ast).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Putting things together,\n",
    "\n",
    "\\begin{align*}\n",
    "C_0&=S_0\\bar F(a-1;N,p_\\ast) -\\bar F(a-1;N,p)e^{-rT}K\\\\\n",
    "&=S_0\\mathbb{Q}^{\\ast}(S_T>K) -\\mathbb{Q}(S_T>K)e^{-rT}K.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Black-Scholes Formula as Continuous Time Limit\n",
    "\n",
    "* Let's consider what happens if we let $N\\rightarrow\\infty$\n",
    "* A first-order Taylor expansion, together with l'Hopital's rule, can be used to show that, for small $\\delta t$,\n",
    "$$\n",
    "p\\approx \\frac{1}{2}\\left( 1+\\sqrt{\\delta t}\\frac{r-\\frac{1}{2}\\sigma ^{2}}{\\sigma }\\right).\n",
    "$$\n",
    "* Similarly,\n",
    "$$\n",
    "p^{\\ast }\\approx \\frac{1}{2}\\left( 1+\\sqrt{\\delta t}\\frac{r+\\frac{1}{2}%\n",
    "\\sigma ^{2}}{\\sigma }\\right) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Next, Let $X_T\\equiv \\log {S_{T}}$. Then, because $R_i$ is either $\\log u$ or $\\log d=-\\log u$, and since $\\log u = \\sigma \\sqrt{\\delta t}$ from the tree calibration, we have\n",
    "\n",
    "\\begin{align*}\n",
    "X_T =\\log S_0 +\\sum_{i=1}^N R_i &=\\log S_0 + k \\log u + (N-k) \\log d\\\\\n",
    "&=\\log S_0 + (2k-N) \\log u \\\\\n",
    "&=\\log S_0 +\\sigma \\sqrt{\\delta t}(2k-N).\n",
    "\\end{align*}\n",
    "\n",
    "* As $k\\sim\\mathrm{Bin}(N,p)$, we have $\\mathbb{E}^\\mathbb{Q}[k]=Np$ and\n",
    "$\\mathrm{var}^{\\mathbb{Q}}[k]=Np(1-p)$.\n",
    "* Thus,\n",
    "\\begin{align*}\n",
    "\\mathbb{E}^\\mathbb{Q}[X_T]&=\\log S_0 + \\sigma\\sqrt{\\delta t} N (2p-1)\\rightarrow \\log S_0+(r-\\frac{1}{2}\\sigma^2)T\\\\\n",
    "\\mathrm{Var}^\\mathbb{Q}[X_T]&=\\sigma^2\\delta t4N p(1-p)\\rightarrow \\sigma^2 T.\n",
    "\\end{align*}\n",
    "<br>\n",
    "The derivation of both the expected value and the variance are below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The expected value of $X_T$ is given by\n",
    "\\begin{align*}\n",
    "\\mathbb{E}^\\mathbb{Q}[X_T]&=\\log S_0 +\\sigma \\sqrt{\\delta t}(2\\mathbb{E}^\\mathbb{Q}[k]-N) \\\\ \n",
    "&= \\log S_0 + \\sigma\\sqrt{\\delta t} (Np - N)\\\\\n",
    "&= \\log S_0 + \\sigma\\sqrt{\\delta t} N (2p-1)\\\\\n",
    "\\end{align*}\n",
    "<br>\n",
    "* As we let $N \\rightarrow \\infty$, this converges to ($\\rightarrow$ means converges to)\n",
    "\\begin{align*}\n",
    "\\mathbb{E}^\\mathbb{Q}[X_T]&=\\log S_0 + \\sigma\\sqrt{\\delta t} N (2p-1)\\\\\n",
    "&\\rightarrow \\log S_0 + \\sigma\\sqrt{\\delta t} N \\left(2 \\left[ \\frac{1}{2}\\left( 1+\\sqrt{\\delta t}\\frac{r-\\frac{1}{2}\\sigma ^{2}}{\\sigma }\\right) \\right]-1\\right)\\\\\n",
    "&= \\log S_0 + \\sigma\\sqrt{\\delta t} N \\sqrt{\\delta t}\\frac{r-\\frac{1}{2}\\sigma ^{2}}{\\sigma }\\\\\n",
    "&=\\log S_0+(r-\\frac{1}{2}\\sigma^2)T,\n",
    "\\end{align*}\n",
    "<br>\n",
    "where we fill in the approximation for $p$ (if $N\\rightarrow\\infty$) that we derived before and use that $\\delta t = T/N$ such that $T=N \\delta t$.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can similarly derive the expression for the variance.\n",
    "\\begin{align*}\n",
    "\\mathrm{Var}^\\mathbb{Q}[X_T] &= \\mathrm{Var}^\\mathbb{Q}[\\sigma \\sqrt{\\delta t}(2k-N)] \\\\\n",
    "&= \\sigma^2 \\delta t\\mathrm{Var}^\\mathbb{Q}[(2k-N)] \\\\\n",
    "&= \\sigma^2 \\delta t 4 \\mathrm{Var}^\\mathbb{Q}[k] \\\\\n",
    "&=\\sigma^2\\delta t4N p(1-p),\n",
    "\\end{align*}\n",
    "<br>\n",
    "using that the variance of a constant (e.g. $\\log S_0$ or $N$) is zero.\n",
    "\n",
    "* Before we take the limit of the variance, note that if $N \\rightarrow\\infty$, then\n",
    "<br>\n",
    "\\begin{align*}\n",
    "1-p \\approx 1 - \\frac{1}{2}\\left( 1+\\sqrt{\\delta t}\\frac{r-\\frac{1}{2}\\sigma ^{2}}{\\sigma }\\right) &= 1 - \\frac{1}{2} -\\frac{1}{2}\\left(\\sqrt{\\delta t}\\frac{r-\\frac{1}{2}\\sigma ^{2}}{\\sigma }\\right) = \\frac{1}{2} -\\frac{1}{2}\\left(\\sqrt{\\delta t}\\frac{r-\\frac{1}{2}\\sigma ^{2}}{\\sigma }\\right) = \\frac{1}{2}\\left( 1-\\sqrt{\\delta t}\\frac{r-\\frac{1}{2}\\sigma ^{2}}{\\sigma }\\right)\n",
    "\\end{align*}\n",
    "<br>\n",
    "\n",
    "* Next, let's work out the limit of $p(1-p)$ if $N\\rightarrow\\infty$. Define $A \\equiv \\sqrt{\\delta t}\\tfrac{r-\\frac{1}{2}\\sigma^2}{\\sigma}$. We have that if $N\\rightarrow \\infty$, then\n",
    "<br>\n",
    "$$\n",
    "p(1-p) \\approx\\frac{1}{2}(1+A)\\frac{1}{2}(1-A) = \\frac{1}{4}(1-A+A-A^2) = \\frac{1}{4}(1-A^2) \\rightarrow \\frac{1}{4},\n",
    "$$\n",
    "because\n",
    "$$\n",
    "A^2 = \\delta t \\left(\\frac{r-\\frac{1}{2}\\sigma^2}{\\sigma}\\right)^2 \\rightarrow 0,\n",
    "$$\n",
    "since $\\delta t \\rightarrow 0$ and $\\left(\\tfrac{r-\\frac{1}{2}\\sigma^2}{\\sigma}\\right)^2$ is a constant.\n",
    "<br>\n",
    "\n",
    "* As we let $N\\rightarrow\\infty$, the variance converges to\n",
    "\\begin{align*}\n",
    "\\mathrm{Var}^\\mathbb{Q}[X_T]&=\\sigma^2\\delta t4N p(1-p) \\\\\n",
    "&\\rightarrow \\sigma^2\\delta t4N \\frac{1}{4} \\\\\n",
    "&= \\sigma^2 T,\n",
    "\\end{align*}\n",
    "where we use that $\\delta t = T/N$ such that $T=N \\delta t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, as $N\\rightarrow \\infty$, the distribution of $X_T$ tends to a normal. This follows from the *central limit theorem* and the fact that $X_T$ is the sum of $N$ i.i.d. terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Thus, as $N\\rightarrow\\infty$,\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{Q}(S_T>K)&=\\mathbb{Q}(X_T>\\log K)=\\mathbb{Q}\\left(\\frac{X_T-\\mathbb{E}^\\mathbb{Q}[X_T]}{\\sqrt{\\mathrm{Var}^\\mathbb{Q}[X_T]}}>\\frac{\\log K-\\mathbb{E}^\\mathbb{Q}[X_T]}{\\sqrt{\\mathrm{Var}^\\mathbb{Q}[X_T]}}\\right)\\\\\n",
    "&=1-\\Phi\\left(\\frac{\\log K-\\mathbb{E}^\\mathbb{Q}[X_T]}{\\sqrt{\\mathrm{Var}^\\mathbb{Q}[X_T]}}\\right)=:1-\\Phi(-d_2)=\\Phi(d_2),\\text{where }\\\\\n",
    "d_2&\\equiv \\frac{\\mathbb{E}^\\mathbb{Q}[X_T]-\\log K}{\\sqrt{\\mathrm{Var}^\\mathbb{Q}[X_T]}}=\\frac{\\log (S_0/K)+(r-\\frac{1}{2}\\sigma^2)T}{\\sigma \\sqrt{T}}.\n",
    "\\end{align*} \n",
    "* In the derivation, we use that $X_T$ is normally distributed, such that $Z_T = \\frac{X_T-\\mathbb{E}^\\mathbb{Q}[X_T]}{\\sqrt{\\mathrm{Var}^\\mathbb{Q}[X_T]}} \\sim N(0,1)$. Further, $1-\\Phi(-d_2)=1-(1-\\Phi(d_2))=\\Phi(d_2)$ holds due to symmetry of the standard normal distribution around zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The same argument can be used to show that as $N\\rightarrow\\infty$,\n",
    "$\n",
    "\\mathbb{Q}^\\ast(S_T>K)=\\Phi(d_1),\n",
    "$\n",
    "where\n",
    "$$\n",
    "d_{1}\\equiv d_{2}+\\sigma \\sqrt{T}=\\frac{\\log (S_{0}/K)+(r+\\tfrac{1}{2}\\sigma ^{2})T%\n",
    "}{\\sigma \\sqrt{T}}.\n",
    "$$\n",
    "\n",
    "* In summary, we have derived the *Black-Scholes formula*\n",
    "\\begin{align*}\n",
    "C_{0}&=S_{0}\\Phi (d_{1})-e^{-rT}K\\Phi (d_{2})\\\\\n",
    "&=:BS(S_{0},K,T,r,\\sigma ).\n",
    "\\end{align*}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
